# ðŸ“¦ Sistema de Ingesta Incremental - Invoice Extractor

## ðŸŽ¯ DescripciÃ³n

Sistema **idempotente**, **tolerante a fallos** y **de bajo impacto** que detecta y procesa **solo las facturas nuevas o modificadas** desde Google Drive, evitando duplicados y reprocesamiento innecesario.

### CaracterÃ­sticas Principales

âœ… **Incremental**: Solo procesa archivos nuevos/modificados desde Ãºltima sincronizaciÃ³n  
âœ… **Idempotente**: No reprocesa facturas ya ingresadas (deduplicaciÃ³n por hash)  
âœ… **Tolerante a fallos**: Reintentos automÃ¡ticos, quarantine para errores  
âœ… **Bajo impacto**: Procesamiento en lotes con pausas configurables  
âœ… **Monitoreable**: Logs JSON estructurados, mÃ©tricas detalladas, auditorÃ­a completa  
âœ… **AutomÃ¡tico**: Compatible con cron para ejecuciÃ³n desatendida  

---

## ðŸ“Š Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Google Drive (Source)                        â”‚
â”‚                   Carpeta con PDFs de facturas                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ (1) Query incremental
                             â”‚     modifiedTime > last_sync
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DriveIncrementalClient                              â”‚
â”‚  â€¢ PaginaciÃ³n automÃ¡tica                                         â”‚
â”‚  â€¢ Reintentos con backoff exponencial                            â”‚
â”‚  â€¢ Rate limiting handling (429)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ (2) Lotes de archivos
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           IncrementalIngestPipeline (Orchestrator)               â”‚
â”‚  â€¢ Descarga en lotes (BATCH_SIZE)                                â”‚
â”‚  â€¢ Pausa entre lotes (SLEEP_BETWEEN_BATCH_SEC)                   â”‚
â”‚  â€¢ Tracking de max_modified_time                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ (3) Procesamiento
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Ingest Pipeline (Existing)                    â”‚
â”‚  â€¢ OCR hÃ­brido (Tesseract + LLM)                                 â”‚
â”‚  â€¢ NormalizaciÃ³n de datos                                        â”‚
â”‚  â€¢ DeduplicaciÃ³n (hash_contenido + drive_file_id)                â”‚
â”‚  â€¢ ValidaciÃ³n de reglas de negocio                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ (4) Persistencia
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       PostgreSQL Database                        â”‚
â”‚  â€¢ facturas: datos extraÃ­dos                                     â”‚
â”‚  â€¢ ingest_events: auditorÃ­a completa                             â”‚
â”‚  â€¢ sync_state: Ãºltimo timestamp procesado                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ (5) Actualizar estado
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    StateStore (DB o File)                        â”‚
â”‚  â€¢ Guardar max_modified_time de archivos OK                      â”‚
â”‚  â€¢ Estrategia MAX_OK_TIME (segura)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸš€ Quick Start

### 1. Aplicar MigraciÃ³n

```bash
bash scripts/apply_incremental_migration.sh
```

### 2. Configurar Variables

Agregar a `.env` (ver [ENV_CONFIG_INCREMENTAL.md](ENV_CONFIG_INCREMENTAL.md)):

```bash
# MÃ­nimo requerido
SYNC_WINDOW_MINUTES=1440
BATCH_SIZE=10
STATE_BACKEND=db
ADVANCE_STRATEGY=MAX_OK_TIME
```

### 3. Validar (Dry Run)

```bash
python scripts/run_ingest_incremental.py --dry-run
```

### 4. Primera EjecuciÃ³n

```bash
python scripts/run_ingest_incremental.py
```

### 5. Configurar Cron

```bash
crontab -e

# Ejecutar cada 30 minutos
*/30 * * * * cd /path/to/project && /path/to/venv/bin/python scripts/run_ingest_incremental.py >> logs/cron.log 2>&1
```

---

## ðŸ“ Componentes Implementados

### Nuevos MÃ³dulos

| Archivo | DescripciÃ³n |
|---------|-------------|
| `src/db/models.py` | Modelo `SyncState` agregado |
| `src/db/repositories.py` | `SyncStateRepository` para estado persistente |
| `src/sync/state_store.py` | AbstracciÃ³n de almacenamiento (DB/File) |
| `src/drive/drive_incremental.py` | Cliente Drive con bÃºsqueda incremental |
| `src/pipeline/ingest_incremental.py` | Pipeline orquestador principal |
| `scripts/run_ingest_incremental.py` | Script ejecutable (CLI) |
| `migrations/001_add_sync_state_table.sql` | MigraciÃ³n para tabla sync_state |

### Scripts Auxiliares

| Script | Uso |
|--------|-----|
| `scripts/apply_incremental_migration.sh` | Aplicar migraciÃ³n SQL |
| `scripts/run_ingest_incremental.py` | Ejecutar ingesta (manual o cron) |

### DocumentaciÃ³n

| Documento | Contenido |
|-----------|-----------|
| `README_INCREMENTAL.md` | Este documento (overview) |
| `INCREMENTAL_SETUP_GUIDE.md` | GuÃ­a paso a paso de setup |
| `ENV_CONFIG_INCREMENTAL.md` | ConfiguraciÃ³n de variables de entorno |

---

## âš™ï¸ ConfiguraciÃ³n

### Variables Clave

#### Control de Flujo

- **`SYNC_WINDOW_MINUTES`** (default: 1440): Ventana de seguridad en minutos para retroceder el timestamp (evita pÃ©rdida de archivos por desfase de relojes)
- **`BATCH_SIZE`** (default: 10): NÃºmero de PDFs procesados simultÃ¡neamente en memoria
- **`SLEEP_BETWEEN_BATCH_SEC`** (default: 10): Pausa en segundos entre lotes (previene calentamiento)
- **`MAX_PAGES_PER_RUN`** (default: 10): LÃ­mite de pÃ¡ginas Drive API por ejecuciÃ³n

#### Estrategia de Avance

- **`ADVANCE_STRATEGY`** (default: MAX_OK_TIME):
  - **`MAX_OK_TIME`** âœ… Recomendado: Avanza al mÃ¡ximo modifiedTime de archivos procesados exitosamente
  - **`CURRENT_TIME`**: Avanza al timestamp actual (puede saltar archivos con errores)

#### Almacenamiento de Estado

- **`STATE_BACKEND`** (default: db):
  - **`db`** âœ… Recomendado: Usa tabla `sync_state` en PostgreSQL
  - **`file`**: Usa archivo JSON local (`STATE_FILE`)

#### Drive API

- **`DRIVE_PAGE_SIZE`** (default: 100): Archivos por pÃ¡gina en resultados Drive
- **`DRIVE_RETRY_MAX`** (default: 5): Reintentos en caso de error
- **`DRIVE_RETRY_BASE_MS`** (default: 500): Tiempo base para backoff exponencial

Ver todas las variables en [ENV_CONFIG_INCREMENTAL.md](ENV_CONFIG_INCREMENTAL.md).

---

## ðŸ”„ Flujo de EjecuciÃ³n

### Secuencia Detallada

1. **InicializaciÃ³n**
   - Cargar configuraciÃ³n desde `.env`
   - Validar acceso a Drive y DB
   - Obtener `last_sync_time` desde StateStore

2. **BÃºsqueda Incremental**
   - Calcular `adjusted_since_time = last_sync_time - SYNC_WINDOW_MINUTES`
   - Query Drive: `modifiedTime > adjusted_since_time`
   - Iterar pÃ¡ginas (mÃ¡ximo `MAX_PAGES_PER_RUN`)

3. **Procesamiento en Lotes**
   - Dividir archivos en lotes de `BATCH_SIZE`
   - Por cada lote:
     - Descargar a temp/
     - Extraer con OCR hÃ­brido
     - Aplicar deduplicaciÃ³n
     - UPSERT en BD
     - Registrar en `ingest_events`
   - Pausa de `SLEEP_BETWEEN_BATCH_SEC` entre lotes

4. **Tracking de Progreso**
   - Mantener `max_modified_time_processed`
   - Solo actualizar con archivos procesados **exitosamente**

5. **ActualizaciÃ³n de Estado**
   - Si hay archivos OK: `last_sync_time = max_modified_time_processed`
   - Si todos fallaron: NO actualizar (reintentar en prÃ³xima ejecuciÃ³n)

6. **Limpieza y Logs**
   - Eliminar archivos temporales
   - Generar resumen con mÃ©tricas
   - Retornar exit code (0=ok, 2=errores parciales, 1=error crÃ­tico)

---

## ðŸ›¡ï¸ Tolerancia a Fallos

### Reintentos AutomÃ¡ticos

- **Drive API**: Hasta `DRIVE_RETRY_MAX` reintentos con backoff exponencial
- **429 (Rate Limit)**: Espera automÃ¡tica con jitter
- **5xx (Server Error)**: Reintento con backoff

### Quarantine System

Archivos con errores se mueven a `data/quarantine/` con metadata:

```json
{
  "file_info": {...},
  "error": "ValueError: Invalid PDF format",
  "timestamp": "20251102_143022",
  "quarantined_at": "2025-11-02T14:30:22Z"
}
```

### Pending Queue

Facturas que requieren revisiÃ³n manual â†’ `data/pending/`:
- Duplicados ambiguos
- ValidaciÃ³n de negocio fallida
- Campos crÃ­ticos faltantes

### Estrategia MAX_OK_TIME

Solo avanza el timestamp con archivos **confirmados OK**. Archivos con error se reintentarÃ¡n en la prÃ³xima ejecuciÃ³n.

**Ejemplo:**

```
Archivos procesados:
  - archivo1.pdf (modifiedTime: 10:00) â†’ OK
  - archivo2.pdf (modifiedTime: 10:05) â†’ ERROR
  - archivo3.pdf (modifiedTime: 10:10) â†’ OK

Resultado:
  last_sync_time = 10:10  â† mÃ¡ximo de archivos OK
  archivo2.pdf se reintentarÃ¡ en prÃ³xima ejecuciÃ³n
```

---

## ðŸ“Š MÃ©tricas y Monitoreo

### MÃ©tricas en Logs JSON

```json
{
  "drive_items_listed_total": 47,
  "drive_pages_fetched_total": 1,
  "files_downloaded": 47,
  "download_errors": 0,
  "batch_errors": 0,
  "invoices_processed_ok_total": 42,
  "invoices_duplicate_total": 1,
  "invoices_revision_total": 2,
  "invoices_ignored_total": 0,
  "invoices_review_total": 1,
  "invoices_error_total": 1,
  "last_sync_time_before": "2025-11-01T10:00:00Z",
  "last_sync_time_after": "2025-11-02T09:45:23Z",
  "duration_seconds": 245.67
}
```

### AuditorÃ­a Completa

Tabla `ingest_events` registra cada paso:

```sql
SELECT 
  drive_file_id,
  etapa,
  nivel,
  decision,
  ts
FROM ingest_events
WHERE drive_file_id = 'abc123'
ORDER BY ts;
```

**Etapas trackeadas:**
- `ingest_start`, `download`, `validate`, `ocr`, `parse`
- `duplicate_check`, `db_upsert`, `ingest_complete`
- `ingest_error`, `revision_created`

---

## ðŸŽ›ï¸ Opciones de CLI

```bash
python scripts/run_ingest_incremental.py [OPTIONS]
```

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `--dry-run` | Validar sin procesar archivos |
| `--folder-id ID` | Override de carpeta Drive |
| `--batch-size N` | Override de tamaÃ±o de lote |
| `--max-pages N` | Override de lÃ­mite de pÃ¡ginas |
| `--sleep-between-batch N` | Override de pausa entre lotes |
| `--advance-strategy S` | Override de estrategia (MAX_OK_TIME\|CURRENT_TIME) |
| `--output-json FILE` | Guardar estadÃ­sticas en JSON |
| `--reset-state` | âš ï¸ Resetear timestamp (forzar rescan) |

### Ejemplos

```bash
# Validar configuraciÃ³n
./scripts/run_ingest_incremental.py --dry-run

# Procesar solo 5 pÃ¡ginas (testing)
./scripts/run_ingest_incremental.py --max-pages 5

# Guardar mÃ©tricas
./scripts/run_ingest_incremental.py --output-json results.json

# Resetear (reprocesar todo)
./scripts/run_ingest_incremental.py --reset-state
```

---

## ðŸ” DeduplicaciÃ³n Multi-nivel

Sistema usa **3 estrategias** de deduplicaciÃ³n (ya existentes, no cambian):

### 1. Por `drive_file_id` (Constraint Ãºnico)

Previene reprocesar mismo archivo Drive.

```sql
UNIQUE INDEX ON facturas(drive_file_id)
```

### 2. Por `hash_contenido` (Semantic hash)

Detecta facturas duplicadas con diferente `drive_file_id`:

```python
hash_contenido = sha256(
  f"{proveedor}|{numero_factura}|{fecha_emision}|{importe_total}"
)
```

```sql
UNIQUE INDEX ON facturas(hash_contenido) WHERE hash_contenido IS NOT NULL
```

### 3. Por lÃ³gica de negocio

Detecta conflictos:
- Mismo proveedor + nÃºmero pero diferente importe
- Misma factura en diferentes carpetas

---

## ðŸ“ˆ Casos de Uso

### EjecuciÃ³n Desatendida (Cron)

**Setup tÃ­pico en producciÃ³n:**

```bash
# Cada 30 minutos
*/30 * * * * cd /path/to/project && /path/to/venv/bin/python scripts/run_ingest_incremental.py >> logs/cron.log 2>&1
```

**Ventajas:**
- Latencia baja (facturas disponibles ~30 min despuÃ©s de subir a Drive)
- Sin intervenciÃ³n manual
- RecuperaciÃ³n automÃ¡tica de errores transitorios

### EjecuciÃ³n Manual

**Para testing, debugging o cargas puntuales:**

```bash
# Seca (sin procesar)
python scripts/run_ingest_incremental.py --dry-run

# Real con lÃ­mite
python scripts/run_ingest_incremental.py --max-pages 3

# Con output JSON
python scripts/run_ingest_incremental.py --output-json results.json
```

### Carga Inicial (Primera Vez)

**Si tienes muchos archivos histÃ³ricos:**

```bash
# 1. Configurar ventana amplia (30 dÃ­as)
# En .env:
SYNC_WINDOW_MINUTES=43200

# 2. Ejecutar con lÃ­mites conservadores
python scripts/run_ingest_incremental.py --batch-size 5 --max-pages 10

# 3. Repetir hasta procesar todos (o dejar en cron)
```

### Re-procesamiento Selectivo

**Si necesitas reprocesar todo:**

```bash
# CUIDADO: Esto forzarÃ¡ reprocesar archivos en SYNC_WINDOW
python scripts/run_ingest_incremental.py --reset-state
```

---

## ðŸ§ª Testing

### Test de ConfiguraciÃ³n

```bash
# Validar sin ejecutar
./scripts/run_ingest_incremental.py --dry-run
```

### Test de ConexiÃ³n Drive

```bash
# Script existente
python scripts/test_connection.py
```

### Test de Base de Datos

```bash
# Verificar tabla sync_state
psql $DATABASE_URL -c "\d sync_state"
psql $DATABASE_URL -c "SELECT * FROM sync_state;"
```

### Test End-to-End

```bash
# Procesar solo 1 pÃ¡gina (mÃ¡x ~100 archivos)
python scripts/run_ingest_incremental.py --max-pages 1

# Verificar resultados
psql $DATABASE_URL -c "SELECT estado, COUNT(*) FROM facturas GROUP BY estado;"
```

---

## ðŸ“š DocumentaciÃ³n Completa

| Documento | DescripciÃ³n |
|-----------|-------------|
| **[INCREMENTAL_SETUP_GUIDE.md](INCREMENTAL_SETUP_GUIDE.md)** | GuÃ­a paso a paso de instalaciÃ³n y setup |
| **[ENV_CONFIG_INCREMENTAL.md](ENV_CONFIG_INCREMENTAL.md)** | Todas las variables de entorno con ejemplos |
| **[migrations/001_add_sync_state_table.sql](migrations/001_add_sync_state_table.sql)** | Script SQL de migraciÃ³n |

---

## ðŸ¤ IntegraciÃ³n con Sistema Existente

El sistema incremental **no modifica** componentes existentes:

âœ… **Reutiliza:**
- `ocr_extractor.py`: Arquitectura hÃ­brida (Tesseract + LLM)
- `parser_normalizer.py`: NormalizaciÃ³n de datos
- `duplicate_manager.py`: DetecciÃ³n de duplicados
- `pipeline/ingest.py`: Procesamiento batch
- Toda la lÃ³gica de validaciÃ³n y BD

âœ… **Agrega:**
- BÃºsqueda incremental en Drive (solo nuevos/modificados)
- Tracking de Ãºltimo timestamp procesado
- OrquestaciÃ³n para ejecuciÃ³n desatendida

---

## ðŸŽ“ Mejores PrÃ¡cticas

### ConfiguraciÃ³n Recomendada

```bash
# ProducciÃ³n (servidor con buenos recursos)
BATCH_SIZE=10
SLEEP_BETWEEN_BATCH_SEC=10
MAX_PAGES_PER_RUN=10
ADVANCE_STRATEGY=MAX_OK_TIME
STATE_BACKEND=db
```

### Monitoreo

1. **Logs**: Revisar `logs/extractor.log` y `logs/cron.log` periÃ³dicamente
2. **MÃ©tricas**: Trackear tasa de errores, duraciÃ³n, throughput
3. **Alertas**: Configurar alertas si `invoices_error_total` > 10%
4. **AuditorÃ­a**: Consultar `ingest_events` para investigar issues

### Mantenimiento

- **Cuarentena**: Revisar `data/quarantine/` semanalmente
- **Pending**: Procesar manualmente archivos en `data/pending/`
- **Logs**: RotaciÃ³n automÃ¡tica (configurable en `logging_conf.py`)
- **Estado**: Backup periÃ³dico de tabla `sync_state`

---

## ðŸš¨ Troubleshooting

Ver [INCREMENTAL_SETUP_GUIDE.md Â§ Troubleshooting](INCREMENTAL_SETUP_GUIDE.md#-troubleshooting) para:

- Error: "No se puede acceder a carpeta Drive"
- Error: "Rate limit exceeded (429)"
- Archivos no se procesan (siempre 0)
- Consumo alto de RAM/CPU
- Y mÃ¡s...

---

## ðŸ“„ Licencia

Este componente forma parte del sistema Invoice Extractor.

---

## ðŸ‘¥ Contribuciones

Ver documento principal `README.md` del proyecto.

---

**Â¡Sistema incremental listo para producciÃ³n! ðŸš€**

Para cualquier duda, consultar la [GuÃ­a de Setup](INCREMENTAL_SETUP_GUIDE.md) o los logs del sistema.


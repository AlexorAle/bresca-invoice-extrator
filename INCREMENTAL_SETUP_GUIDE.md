# üì¶ Gu√≠a de Setup - Sistema de Ingesta Incremental

Esta gu√≠a te ayudar√° a configurar y poner en marcha el **sistema de ingesta incremental** desde Google Drive.

## üìã Tabla de Contenidos

1. [Requisitos Previos](#requisitos-previos)
2. [Instalaci√≥n Paso a Paso](#instalaci√≥n-paso-a-paso)
3. [Configuraci√≥n](#configuraci√≥n)
4. [Primera Ejecuci√≥n](#primera-ejecuci√≥n)
5. [Configurar Cron](#configurar-cron)
6. [Troubleshooting](#troubleshooting)
7. [Comandos √ötiles](#comandos-√∫tiles)

---

## ‚úÖ Requisitos Previos

Antes de comenzar, aseg√∫rate de tener:

- [x] PostgreSQL instalado y corriendo
- [x] Base de datos creada y `DATABASE_URL` configurada en `.env`
- [x] Google Service Account con acceso a Drive (archivo JSON)
- [x] Python 3.8+ con virtualenv activado
- [x] Dependencias instaladas (`pip install -r requirements.txt`)
- [x] Sistema OCR existente funcionando (Tesseract + Ollama)

---

## üöÄ Instalaci√≥n Paso a Paso

### Paso 1: Aplicar Migraci√≥n de Base de Datos

La ingesta incremental requiere una nueva tabla `sync_state` para trackear el √∫ltimo timestamp de sincronizaci√≥n.

```bash
# Opci√≥n A: Script autom√°tico (recomendado)
bash scripts/apply_incremental_migration.sh

# Opci√≥n B: Manual con psql
psql $DATABASE_URL -f migrations/001_add_sync_state_table.sql
```

**Verificar que la tabla fue creada:**

```bash
psql $DATABASE_URL -c "\d sync_state"
```

Deber√≠as ver:

```
                Table "public.sync_state"
   Column    |           Type           | Modifiers
-------------+--------------------------+-----------
 key         | text                     | not null
 value       | text                     | not null
 updated_at  | timestamp with time zone | default now()
```

### Paso 2: Configurar Variables de Entorno

Agregar las nuevas variables al archivo `.env`. Ver [ENV_CONFIG_INCREMENTAL.md](ENV_CONFIG_INCREMENTAL.md) para detalles completos.

**M√≠nimo requerido:**

```bash
# Agregar a .env:

# Ingesta incremental
SYNC_WINDOW_MINUTES=1440
BATCH_SIZE=10
SLEEP_BETWEEN_BATCH_SEC=10
MAX_PAGES_PER_RUN=10
ADVANCE_STRATEGY=MAX_OK_TIME

# Estado
STATE_BACKEND=db

# Drive API
DRIVE_PAGE_SIZE=100
DRIVE_RETRY_MAX=5
DRIVE_RETRY_BASE_MS=500

# Directorios
QUARANTINE_DIR=data/quarantine
PENDING_DIR=data/pending
```

### Paso 3: Crear Directorios

```bash
mkdir -p data/quarantine data/pending state logs
```

### Paso 4: Hacer Script Ejecutable

```bash
chmod +x scripts/run_ingest_incremental.py
chmod +x scripts/apply_incremental_migration.sh
```

---

## ‚öôÔ∏è Configuraci√≥n

### Configuraci√≥n por Defecto (Recomendada)

La configuraci√≥n por defecto est√° optimizada para:
- Ejecuciones cada 30-60 minutos desde cron
- Servidor con recursos moderados (8GB RAM, 4 cores)
- Procesar ~100-500 facturas por d√≠a

### Ajustar para Alto Volumen

Si procesas **muchas facturas** (>1000/d√≠a):

```bash
BATCH_SIZE=20                # M√°s archivos por lote
MAX_PAGES_PER_RUN=20         # M√°s p√°ginas por ejecuci√≥n
SLEEP_BETWEEN_BATCH_SEC=5    # Menos pausa entre lotes
DRIVE_PAGE_SIZE=200          # M√°s archivos por p√°gina API
```

### Ajustar para Recursos Limitados

Si el servidor tiene **pocos recursos** (<4GB RAM):

```bash
BATCH_SIZE=5                 # Menos archivos en memoria
MAX_PAGES_PER_RUN=5          # Menos p√°ginas por run
SLEEP_BETWEEN_BATCH_SEC=15   # M√°s pausa para CPU
```

### Ajustar para Primera Carga Masiva

Si es la **primera ejecuci√≥n** con muchos archivos hist√≥ricos:

```bash
SYNC_WINDOW_MINUTES=43200    # 30 d√≠as hacia atr√°s
MAX_PAGES_PER_RUN=50         # Procesar m√°s archivos
BATCH_SIZE=5                 # Pero en lotes peque√±os
```

---

## üéØ Primera Ejecuci√≥n

### 1. Validar Configuraci√≥n (Dry Run)

**Siempre ejecutar primero en modo dry-run:**

```bash
python scripts/run_ingest_incremental.py --dry-run
```

Esto validar√°:
- ‚úÖ Variables de entorno configuradas
- ‚úÖ Acceso a Google Drive
- ‚úÖ Conexi√≥n a base de datos
- ‚úÖ N√∫mero de archivos a procesar

**Salida esperada:**

```
================================================================================
  üöÄ INGESTA INCREMENTAL - GOOGLE DRIVE
================================================================================

‚è∞ Inicio: 2025-11-02T10:00:00Z
üíª Host: server-prod

================================================================================
  VALIDACI√ìN DE CONFIGURACI√ìN
================================================================================

‚úÖ GOOGLE_SERVICE_ACCOUNT_FILE: /path/to/keys/service_account.json
‚úÖ GOOGLE_DRIVE_FOLDER_ID: 1aBcDeFgHiJkLmNoPqRsTuV...
‚úÖ DATABASE_URL: postgresql://invoice_user@localhost...
‚úÖ STATE_BACKEND: db

‚úÖ Configuraci√≥n v√°lida

================================================================================
  DRY RUN - INFORMACI√ìN
================================================================================

üìÅ Carpeta objetivo: 1aBcDeFgHiJkLmNoPqRsTuV
‚è∞ √öltima sincronizaci√≥n: N/A (primera ejecuci√≥n)
üì¶ Tama√±o de lote: 10
üìÑ M√°ximo de p√°ginas: 10
‚è±Ô∏è  Pausa entre lotes: 10s
üîÑ Estrategia de avance: MAX_OK_TIME

üîç Validando acceso a carpeta...
‚úÖ Acceso validado

üîç Contando archivos a procesar...
üìä Archivos a procesar: 47

‚ÑπÔ∏è  Dry run completado. No se procesaron archivos.
```

### 2. Primera Ejecuci√≥n Real

Si el dry-run fue exitoso:

```bash
python scripts/run_ingest_incremental.py
```

**Monitorear en tiempo real:**

```bash
# En otra terminal
tail -f logs/extractor.log | grep -E 'INFO|ERROR|WARNING'
```

### 3. Verificar Resultados

Al finalizar, ver√°s un resumen:

```
================================================================================
  üìä RESUMEN DE EJECUCI√ìN
================================================================================

‚è±Ô∏è  Duraci√≥n: 245.67s
üìÑ P√°ginas consultadas: 1
üì• Archivos listados: 47
üíæ Archivos descargados: 47

‚úÖ Procesados OK: 42
üîÑ Revisiones: 2
üìã Duplicados: 1
‚ö†Ô∏è  Para revisi√≥n: 1
üö´ Ignorados: 0
‚ùå Errores: 1

üïê Timestamp anterior: N/A
üïë Timestamp nuevo: 2025-11-02T09:45:23Z

‚úÖ Ejecuci√≥n completada exitosamente
```

**Verificar en base de datos:**

```bash
psql $DATABASE_URL -c "SELECT COUNT(*) FROM facturas WHERE estado = 'procesado';"
psql $DATABASE_URL -c "SELECT * FROM sync_state WHERE key = 'drive_last_sync_time';"
```

---

## ‚è∞ Configurar Cron

### Agregar al Crontab

```bash
# Editar crontab
crontab -e
```

### Ejemplos de Configuraci√≥n

#### Cada 30 minutos (Recomendado)

```bash
*/30 * * * * cd /home/user/invoice-extractor && /home/user/invoice-extractor/venv/bin/python scripts/run_ingest_incremental.py >> logs/cron.log 2>&1
```

#### Cada hora

```bash
0 * * * * cd /home/user/invoice-extractor && /home/user/invoice-extractor/venv/bin/python scripts/run_ingest_incremental.py >> logs/cron.log 2>&1
```

#### Cada 4 horas

```bash
0 */4 * * * cd /home/user/invoice-extractor && /home/user/invoice-extractor/venv/bin/python scripts/run_ingest_incremental.py >> logs/cron.log 2>&1
```

#### Horarios espec√≠ficos (d√≠as laborales)

```bash
# Lunes a Viernes a las 9 AM, 1 PM y 5 PM
0 9,13,17 * * 1-5 cd /home/user/invoice-extractor && /home/user/invoice-extractor/venv/bin/python scripts/run_ingest_incremental.py >> logs/cron.log 2>&1
```

### Verificar Cron Activo

```bash
# Listar jobs activos
crontab -l

# Ver logs de ejecuciones
tail -f logs/cron.log
```

---

## üîß Troubleshooting

### Error: "No se puede acceder a carpeta Drive"

**Causa:** Service Account no tiene permisos sobre la carpeta.

**Soluci√≥n:**
1. Ir a Google Drive en web
2. Compartir la carpeta con el email del Service Account
3. Dar permisos de "Lector" o "Editor"

```bash
# Ver email del service account:
cat keys/service_account.json | grep client_email
```

### Error: "Rate limit exceeded (429)"

**Causa:** Demasiadas requests a Drive API.

**Soluci√≥n:**
```bash
# En .env, aumentar delays:
DRIVE_RETRY_BASE_MS=1000
SLEEP_BETWEEN_BATCH_SEC=20
DRIVE_PAGE_SIZE=50
```

### Error: "Database connection failed"

**Causa:** PostgreSQL no accesible o credenciales incorrectas.

**Soluci√≥n:**
```bash
# Verificar que PostgreSQL est√° corriendo
sudo systemctl status postgresql

# Test de conexi√≥n
psql $DATABASE_URL -c "SELECT 1;"
```

### Archivos no se procesan (siempre 0)

**Causa:** `last_sync_time` est√° muy adelantado.

**Soluci√≥n:**
```bash
# Ver timestamp actual
psql $DATABASE_URL -c "SELECT * FROM sync_state WHERE key = 'drive_last_sync_time';"

# Resetear (CUIDADO: reprocesar√° todo en la ventana)
python scripts/run_ingest_incremental.py --reset-state
```

### Consumo alto de RAM/CPU

**Causa:** Lotes muy grandes o Ollama/Tesseract sin l√≠mites.

**Soluci√≥n:**
```bash
# Reducir carga en .env:
BATCH_SIZE=3
SLEEP_BETWEEN_BATCH_SEC=20
MAX_PAGES_PER_RUN=5
```

---

## üõ†Ô∏è Comandos √ötiles

### Ver Estado Actual

```bash
# √öltimo timestamp de sincronizaci√≥n (DB)
psql $DATABASE_URL -c "SELECT key, value, updated_at FROM sync_state WHERE key = 'drive_last_sync_time';"

# √öltimas facturas procesadas
psql $DATABASE_URL -c "SELECT drive_file_name, estado, creado_en FROM facturas ORDER BY creado_en DESC LIMIT 10;"

# Eventos recientes
psql $DATABASE_URL -c "SELECT etapa, nivel, detalle, ts FROM ingest_events ORDER BY ts DESC LIMIT 20;"
```

### Estad√≠sticas

```bash
# Facturas por estado
psql $DATABASE_URL -c "SELECT estado, COUNT(*) FROM facturas GROUP BY estado;"

# Facturas por d√≠a (√∫ltimos 7 d√≠as)
psql $DATABASE_URL -c "SELECT DATE(creado_en) as fecha, COUNT(*) FROM facturas WHERE creado_en > NOW() - INTERVAL '7 days' GROUP BY fecha ORDER BY fecha;"
```

### Ejecutar con Opciones

```bash
# Procesar solo 5 p√°ginas
python scripts/run_ingest_incremental.py --max-pages 5

# Usar lotes de 20
python scripts/run_ingest_incremental.py --batch-size 20

# Guardar estad√≠sticas en JSON
python scripts/run_ingest_incremental.py --output-json results.json
```

### Logs

```bash
# Ver logs en tiempo real
tail -f logs/extractor.log

# Ver solo errores
tail -f logs/extractor.log | grep ERROR

# Ver m√©tricas (si LOG_JSON=true)
tail -f logs/extractor.log | jq '.level, .message'

# Contar errores hoy
grep ERROR logs/extractor.log | grep $(date +%Y-%m-%d) | wc -l
```

### Resetear Sistema (CUIDADO)

```bash
# Resetear timestamp (reprocesar√° archivos en ventana)
python scripts/run_ingest_incremental.py --reset-state

# Limpiar cuarentena
rm -rf data/quarantine/*

# Limpiar pending
rm -rf data/pending/*
```

---

## üìä Monitoreo y M√©tricas

### M√©tricas Clave

El sistema expone estas m√©tricas en logs JSON:

```json
{
  "drive_items_listed_total": 47,
  "drive_pages_fetched_total": 1,
  "files_downloaded": 47,
  "invoices_processed_ok_total": 42,
  "invoices_duplicate_total": 1,
  "invoices_revision_total": 2,
  "invoices_error_total": 1,
  "duration_seconds": 245.67
}
```

### Alertas Recomendadas

Configurar alertas si:
- `invoices_error_total > 10%` del total
- `download_errors > 5`
- `duration_seconds > 600` (m√°s de 10 min)
- √öltima ejecuci√≥n hace m√°s de 2 horas (si cron cada 30 min)

---

## üéì Mejores Pr√°cticas

1. **Siempre usar dry-run primero** en nuevas configuraciones
2. **Monitorear los primeros d√≠as** despu√©s de poner en cron
3. **Revisar cuarentena** semanalmente para detectar patrones de error
4. **Backup de `sync_state`** antes de cambios mayores
5. **Logs con rotaci√≥n** para no llenar disco
6. **Establecer l√≠mites** (`MAX_PAGES_PER_RUN`) para evitar ejecuciones muy largas

---

## üìû Soporte

Si encuentras problemas:

1. Revisar logs: `logs/extractor.log` y `logs/cron.log`
2. Ejecutar con `--dry-run` para validar configuraci√≥n
3. Verificar eventos en DB: `SELECT * FROM ingest_events ORDER BY ts DESC LIMIT 50;`
4. Consultar [ENV_CONFIG_INCREMENTAL.md](ENV_CONFIG_INCREMENTAL.md) para configuraci√≥n detallada

---

## ‚úÖ Checklist Post-Setup

Despu√©s de configurar, verificar:

- [ ] Migraci√≥n aplicada: `psql $DATABASE_URL -c "\d sync_state"`
- [ ] Variables en `.env` configuradas
- [ ] Dry-run exitoso
- [ ] Primera ejecuci√≥n manual exitosa
- [ ] Cron configurado y activo: `crontab -l`
- [ ] Logs rotando correctamente: `ls -lh logs/`
- [ ] Directorios creados: `ls -d data/*`

**¬°Sistema listo para producci√≥n! üöÄ**


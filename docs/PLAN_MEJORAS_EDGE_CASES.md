# Plan de Implementaci√≥n: Mejoras de Edge Cases

**Fecha:** 9 de noviembre de 2025  
**Objetivo:** Implementar mejoras cr√≠ticas y medias para robustecer el sistema

---

## ESTRATEGIA DE IMPLEMENTACI√ìN

- **Enfoque:** Fases incrementales con pruebas completas antes de avanzar
- **Principio:** Una fase a la vez, verificar funcionamiento, luego avanzar
- **Testing:** Cada fase incluye pruebas unitarias, de integraci√≥n y de escenario real

---

## FASE 1: Protecci√≥n contra Ejecuciones Concurrentes (7.4)

**Prioridad:** üî¥ ALTA  
**Esfuerzo:** Bajo  
**Riesgo de implementaci√≥n:** Bajo

### Objetivo
Prevenir que m√∫ltiples instancias del job se ejecuten simult√°neamente, evitando condiciones de carrera y procesamiento duplicado.

### Implementaci√≥n

#### 1.1 Instalar dependencia
```bash
pip install filelock
```

#### 1.2 Crear m√≥dulo de lock
**Archivo:** `src/pipeline/job_lock.py` (NUEVO)
- Usar `filelock.FileLock` para crear lock file
- Lock file: `data/.job_running.lock`
- Timeout: 5 minutos (si otro proceso muere, el lock se libera)
- Context manager para manejo seguro

#### 1.3 Integrar en pipeline incremental
**Archivo:** `src/pipeline/ingest_incremental.py`
- Agregar lock al inicio de `run()`
- Liberar lock en `finally` block
- Si lock est√° activo ‚Üí log warning y salir con c√≥digo 1

#### 1.4 Integrar en scripts de ejecuci√≥n
**Archivos:** 
- `scripts/run_ingest_incremental.py`
- `scripts/monitorear_drive.sh`
- Verificar lock antes de ejecutar

### Pruebas

#### Test 1.1: Ejecuci√≥n √∫nica
```bash
# Terminal 1
python scripts/run_ingest_incremental.py

# Terminal 2 (mientras corre el primero)
python scripts/run_ingest_incremental.py
# Esperado: Segundo proceso debe detectar lock y salir con mensaje claro
```

#### Test 1.2: Lock liberado despu√©s de crash
```bash
# Simular crash
python scripts/run_ingest_incremental.py &
PID=$!
sleep 5
kill -9 $PID

# Verificar que lock se libera despu√©s de timeout
# Esperado: Lock file debe desaparecer o ser liberable despu√©s de timeout
```

#### Test 1.3: Ejecuci√≥n normal con lock
```bash
# Ejecutar job normal
python scripts/run_ingest_incremental.py
# Esperado: Debe ejecutarse normalmente, lock se crea y libera correctamente
```

#### Test 1.4: Verificar en logs
```bash
# Verificar que logs muestran informaci√≥n de lock
grep -i "lock" logs/extractor.log
# Esperado: Logs claros sobre adquisici√≥n/liberaci√≥n de lock
```

### Criterios de √âxito
- ‚úÖ Segundo proceso detecta lock y sale sin procesar
- ‚úÖ Lock se libera correctamente despu√©s de ejecuci√≥n normal
- ‚úÖ Lock se libera despu√©s de timeout si proceso muere
- ‚úÖ Logs claros sobre estado del lock
- ‚úÖ No hay condiciones de carrera en pruebas concurrentes

### Archivos a Modificar/Crear
- `src/pipeline/job_lock.py` (NUEVO)
- `src/pipeline/ingest_incremental.py`
- `scripts/run_ingest_incremental.py`
- `requirements.txt` (agregar filelock)

---

## FASE 2: Validaci√≥n de Tama√±o de PDF (9.2)

**Prioridad:** üî¥ ALTA  
**Esfuerzo:** Bajo  
**Riesgo de implementaci√≥n:** Bajo

### Objetivo
Validar tama√±o de archivo antes de descargar/procesar para evitar timeouts y consumo excesivo de recursos.

### Implementaci√≥n

#### 2.1 Agregar variable de entorno
```env
MAX_PDF_SIZE_MB=50  # L√≠mite por defecto
```

#### 2.2 Validar tama√±o en DriveClient
**Archivo:** `src/drive_client.py`
- En `download_file()`, verificar `file_info.get('size')` antes de descargar
- Convertir a MB y comparar con l√≠mite
- Si excede ‚Üí retornar `False` y log error

#### 2.3 Validar en pipeline
**Archivo:** `src/pipeline/ingest.py`
- Antes de descargar, verificar tama√±o desde metadata de Drive
- Si excede ‚Üí marcar como error, registrar evento, mover a cuarentena
- Mensaje: "Archivo excede tama√±o m√°ximo permitido: X MB"

#### 2.4 Agregar estad√≠stica
**Archivo:** `src/pipeline/ingest_incremental.py`
- Contador: `files_rejected_size`
- Incluir en estad√≠sticas finales

### Pruebas

#### Test 2.1: PDF normal (dentro del l√≠mite)
```bash
# Procesar PDF de 5MB
# Esperado: Se procesa normalmente
```

#### Test 2.2: PDF grande (excede l√≠mite)
```bash
# Crear PDF de 60MB (o configurar l√≠mite a 10MB y usar PDF de 15MB)
# Esperado: 
# - No se descarga
# - Se marca como error
# - Mensaje claro en logs
# - Estad√≠stica files_rejected_size incrementada
```

#### Test 2.3: L√≠mite configurable
```bash
# Configurar MAX_PDF_SIZE_MB=10
# Procesar PDF de 15MB
# Esperado: Rechazado

# Configurar MAX_PDF_SIZE_MB=100
# Procesar mismo PDF
# Esperado: Aceptado
```

#### Test 2.4: Sin informaci√≥n de tama√±o
```bash
# Procesar archivo donde Drive no devuelve size
# Esperado: Se procesa normalmente (no falla por falta de size)
```

### Criterios de √âxito
- ‚úÖ PDFs grandes se rechazan antes de descargar
- ‚úÖ Mensaje de error claro en logs
- ‚úÖ Estad√≠stica se incrementa correctamente
- ‚úÖ L√≠mite es configurable v√≠a variable de entorno
- ‚úÖ PDFs normales no se afectan

### Archivos a Modificar
- `src/drive_client.py`
- `src/pipeline/ingest.py`
- `src/pipeline/ingest_incremental.py`
- `.env.example` (documentar MAX_PDF_SIZE_MB)

---

## FASE 3: Script de Reprocesamiento Manual (10.5)

**Prioridad:** üî¥ ALTA  
**Esfuerzo:** Bajo  
**Riesgo de implementaci√≥n:** Bajo

### Objetivo
Crear herramienta CLI para reprocesar facturas espec√≠ficas manualmente sin modificar BD directamente.

### Implementaci√≥n

#### 3.1 Crear script CLI
**Archivo:** `scripts/reprocess_invoice.py` (NUEVO)
- Argumentos:
  - `--drive-file-id`: ID del archivo en Drive (requerido)
  - `--force`: Forzar reprocesamiento aunque est√© en "procesado"
  - `--reset-attempts`: Resetear contador de intentos
- Funcionalidad:
  - Buscar factura en BD por `drive_file_id`
  - Si no existe ‚Üí error
  - Si existe y est√° en "procesado" sin `--force` ‚Üí error
  - Descargar desde Drive
  - Reprocesar usando `process_batch()`
  - Mostrar resultado

#### 3.2 Integrar con sistema existente
- Reutilizar `process_batch()` de `ingest.py`
- Usar `DriveClient.get_file_by_id()`
- Usar `FacturaRepository` para consultas

#### 3.3 Agregar opci√≥n de dry-run
- `--dry-run`: Mostrar qu√© se har√≠a sin ejecutar

### Pruebas

#### Test 3.1: Reprocesar factura en "revisar"
```bash
# Obtener drive_file_id de factura en "revisar"
python scripts/reprocess_invoice.py --drive-file-id <id>
# Esperado: 
# - Descarga archivo
# - Reprocesa
# - Muestra resultado
# - Actualiza estado si pasa validaci√≥n
```

#### Test 3.2: Reprocesar factura en "procesado" (sin force)
```bash
python scripts/reprocess_invoice.py --drive-file-id <id_procesado>
# Esperado: Error claro indicando que necesita --force
```

#### Test 3.3: Reprocesar con --force
```bash
python scripts/reprocess_invoice.py --drive-file-id <id> --force
# Esperado: Reprocesa aunque est√© en "procesado"
```

#### Test 3.4: Resetear intentos
```bash
python scripts/reprocess_invoice.py --drive-file-id <id> --reset-attempts
# Esperado: 
# - reprocess_attempts se resetea a 0
# - Se reprocesa
```

#### Test 3.5: Factura inexistente
```bash
python scripts/reprocess_invoice.py --drive-file-id "inexistente"
# Esperado: Error claro indicando que no existe
```

#### Test 3.6: Dry-run
```bash
python scripts/reprocess_invoice.py --drive-file-id <id> --dry-run
# Esperado: Muestra informaci√≥n sin ejecutar
```

### Criterios de √âxito
- ‚úÖ Script funciona con todos los argumentos
- ‚úÖ Maneja errores correctamente (factura no existe, ya procesada, etc.)
- ‚úÖ Reprocesa correctamente facturas en "revisar"
- ‚úÖ ‚úÖ Opci√≥n --force funciona para facturas procesadas
- ‚úÖ Dry-run muestra informaci√≥n sin ejecutar
- ‚úÖ Logs claros de lo que hace

### Archivos a Crear/Modificar
- `scripts/reprocess_invoice.py` (NUEVO)
- `README.md` (documentar script)

---

## FASE 4: Detecci√≥n de Archivos Eliminados de Drive (2.5)

**Prioridad:** üî¥ ALTA  
**Esfuerzo:** Medio  
**Riesgo de implementaci√≥n:** Medio

### Objetivo
Detectar y marcar facturas en BD cuyos archivos fueron eliminados de Drive, evitando crecimiento indefinido de registros hu√©rfanos.

### Implementaci√≥n

#### 4.1 Agregar campo en BD
**Migraci√≥n:** `migrations/005_add_deleted_flag.sql`
- Agregar columna: `deleted_from_drive BOOLEAN DEFAULT FALSE`
- Agregar √≠ndice: `idx_facturas_deleted` en `deleted_from_drive`
- Actualizar modelo: `src/db/models.py`

#### 4.2 Crear job de reconciliaci√≥n
**Archivo:** `scripts/reconcile_deleted_files.py` (NUEVO)
- Consultar todas las facturas en BD (no eliminadas)
- Para cada una, verificar existencia en Drive usando `get_file_by_id()`
- Si no existe ‚Üí marcar `deleted_from_drive = TRUE`
- Registrar evento de auditor√≠a
- Opci√≥n: `--dry-run` para ver qu√© se marcar√≠a

#### 4.3 Agregar a cron (opcional)
- Ejecutar semanalmente (domingos 2 AM)
- O ejecutar manualmente cuando sea necesario

#### 4.4 Filtrar en queries (opcional)
- Modificar queries de reportes para excluir `deleted_from_drive = TRUE`
- O crear vista que filtre autom√°ticamente

### Pruebas

#### Test 4.1: Archivo existe en Drive
```bash
# Ejecutar reconciliaci√≥n
python scripts/reconcile_deleted_files.py
# Esperado: No marca nada como eliminado
```

#### Test 4.2: Archivo eliminado de Drive
```bash
# 1. Crear factura en BD
# 2. Eliminar archivo de Drive manualmente
# 3. Ejecutar reconciliaci√≥n
python scripts/reconcile_deleted_files.py
# Esperado: 
# - Marca deleted_from_drive = TRUE
# - Registra evento de auditor√≠a
# - Log claro
```

#### Test 4.3: Dry-run
```bash
python scripts/reconcile_deleted_files.py --dry-run
# Esperado: Muestra qu√© se marcar√≠a sin ejecutar
```

#### Test 4.4: Performance con muchas facturas
```bash
# Ejecutar con 100+ facturas
# Esperado: 
# - No bloquea BD
# - Procesa en lotes si es necesario
# - Tiempo razonable (< 5 min para 1000 facturas)
```

#### Test 4.5: Verificar en BD
```sql
-- Verificar facturas marcadas como eliminadas
SELECT COUNT(*) FROM facturas WHERE deleted_from_drive = TRUE;
-- Esperado: Solo las que realmente fueron eliminadas
```

### Criterios de √âxito
- ‚úÖ Detecta correctamente archivos eliminados
- ‚úÖ Marca correctamente en BD
- ‚úÖ Registra eventos de auditor√≠a
- ‚úÖ Dry-run funciona
- ‚úÖ Performance aceptable (no bloquea sistema)
- ‚úÖ No marca incorrectamente archivos que existen

### Archivos a Crear/Modificar
- `migrations/005_add_deleted_flag.sql` (NUEVO)
- `src/db/models.py`
- `scripts/reconcile_deleted_files.py` (NUEVO)
- `README.md` (documentar job)

---

## FASE 5: Limpieza Autom√°tica de Facturas "Pendiente" (6.2)

**Prioridad:** üü° MEDIA  
**Esfuerzo:** Bajo  
**Riesgo de implementaci√≥n:** Bajo

### Objetivo
Cambiar autom√°ticamente facturas en estado "pendiente" > 24 horas a "error" para evitar facturas stuck indefinidamente.

### Implementaci√≥n

#### 5.1 Crear funci√≥n de limpieza
**Archivo:** `src/db/repositories.py`
- M√©todo: `cleanup_stuck_pending_invoices(hours: int = 24)`
- Query: facturas con `estado = 'pendiente'` y `actualizado_en < ahora - hours`
- Actualizar: `estado = 'error'`, `error_msg = 'Factura en pendiente > 24h, marcada como error'`
- Retornar: n√∫mero de facturas actualizadas

#### 5.2 Integrar en job incremental
**Archivo:** `src/pipeline/ingest_incremental.py`
- Al inicio de `run()`, antes de procesar archivos
- Ejecutar limpieza
- Log: n√∫mero de facturas limpiadas

#### 5.3 Variable de entorno
```env
CLEANUP_PENDING_HOURS=24  # Horas antes de marcar como error
```

### Pruebas

#### Test 5.1: Factura pendiente < 24h
```bash
# Crear factura en estado "pendiente" hace 12 horas
# Ejecutar job
# Esperado: No cambia estado
```

#### Test 5.2: Factura pendiente > 24h
```bash
# Crear factura en estado "pendiente" hace 30 horas
# Ejecutar job
# Esperado: 
# - Estado cambia a "error"
# - error_msg indica raz√≥n
# - Log muestra factura limpiada
```

#### Test 5.3: M√∫ltiples facturas
```bash
# Crear 5 facturas pendientes > 24h
# Ejecutar job
# Esperado: Todas se actualizan
```

#### Test 5.4: Configuraci√≥n de horas
```bash
# Configurar CLEANUP_PENDING_HOURS=12
# Crear factura pendiente hace 15 horas
# Ejecutar job
# Esperado: Se marca como error
```

### Criterios de √âxito
- ‚úÖ Facturas > 24h se marcan como error
- ‚úÖ Facturas < 24h no se afectan
- ‚úÖ Logs claros de limpieza
- ‚úÖ Configurable v√≠a variable de entorno
- ‚úÖ No afecta otras facturas

### Archivos a Modificar
- `src/db/repositories.py`
- `src/pipeline/ingest_incremental.py`
- `.env.example` (documentar CLEANUP_PENDING_HOURS)

---

## FASE 6: Validaci√≥n de Espacio en Disco (9.4)

**Prioridad:** üü° MEDIA  
**Esfuerzo:** Bajo  
**Riesgo de implementaci√≥n:** Bajo

### Objetivo
Validar espacio en disco antes de procesar para evitar fallos por falta de espacio.

### Implementaci√≥n

#### 6.1 Crear funci√≥n de validaci√≥n
**Archivo:** `src/utils/disk_space.py` (NUEVO)
- Funci√≥n: `check_disk_space(min_percent: int = 10, critical_percent: int = 5)`
- Usar `shutil.disk_usage()` para obtener espacio disponible
- Retornar: `(has_space, is_critical, available_gb, total_gb)`
- Log: advertencia si < 10%, error si < 5%

#### 6.2 Integrar en pipeline
**Archivo:** `src/pipeline/ingest_incremental.py`
- Al inicio de `run()`, verificar espacio
- Si < 5% ‚Üí salir con error, no procesar
- Si < 10% ‚Üí advertencia pero continuar
- Log: espacio disponible y porcentaje

#### 6.3 Variables de entorno
```env
DISK_SPACE_WARNING_PERCENT=10  # Advertencia si < X%
DISK_SPACE_CRITICAL_PERCENT=5  # Error si < X%
```

### Pruebas

#### Test 6.1: Espacio suficiente
```bash
# Ejecutar job con espacio > 10%
# Esperado: Se ejecuta normalmente
```

#### Test 6.2: Espacio bajo (advertencia)
```bash
# Simular espacio < 10% (o configurar l√≠mite alto)
# Ejecutar job
# Esperado: 
# - Advertencia en logs
# - Contin√∫a ejecut√°ndose
```

#### Test 6.3: Espacio cr√≠tico (error)
```bash
# Simular espacio < 5%
# Ejecutar job
# Esperado: 
# - Error en logs
# - Job sale sin procesar
# - C√≥digo de salida != 0
```

#### Test 6.4: Configuraci√≥n personalizada
```bash
# Configurar DISK_SPACE_CRITICAL_PERCENT=15
# Simular espacio < 15%
# Esperado: Sale con error
```

### Criterios de √âxito
- ‚úÖ Detecta espacio bajo correctamente
- ‚úÖ Advertencia si < 10%
- ‚úÖ Error y salida si < 5%
- ‚úÖ Configurable v√≠a variables de entorno
- ‚úÖ Logs claros con espacio disponible

### Archivos a Crear/Modificar
- `src/utils/disk_space.py` (NUEVO)
- `src/pipeline/ingest_incremental.py`
- `.env.example` (documentar variables)

---

## FASE 7: Detecci√≥n de Cambios en Archivos en Cuarentena (8.3)

**Prioridad:** üü° MEDIA  
**Esfuerzo:** Medio  
**Riesgo de implementaci√≥n:** Medio

### Objetivo
Detectar cuando archivos en cuarentena se corrigen en Drive y reprocesarlos autom√°ticamente.

### Implementaci√≥n

#### 7.1 Extender sistema de reprocesamiento
**Archivo:** `src/pipeline/ingest_incremental.py`
- Modificar `_reprocess_review_invoices()` para incluir archivos en cuarentena
- Consultar facturas con `estado IN ('revisar', 'error')` que tienen archivo en cuarentena
- Verificar si archivo fue modificado en Drive (`modifiedTime`)
- Si fue modificado ‚Üí reprocesar

#### 7.2 Consultar cuarentena
**Archivo:** `src/db/repositories.py`
- M√©todo: `get_facturas_en_cuarentena_para_reprocesar()`
- Query: facturas con estado problem√°tico que tienen archivo en `data/quarantine/`
- Filtrar por `modifiedTime` en Drive > `actualizado_en` en BD

#### 7.3 Integrar con reprocesamiento existente
- Reutilizar l√≥gica de `_reprocess_review_invoices()`
- Agregar flag: `include_quarantine=True` (configurable)

### Pruebas

#### Test 7.1: Archivo en cuarentena sin cambios
```bash
# Archivo en cuarentena, no modificado en Drive
# Ejecutar job
# Esperado: No se reprocesa
```

#### Test 7.2: Archivo en cuarentena con cambios
```bash
# 1. Archivo en cuarentena
# 2. Modificar archivo en Drive
# 3. Ejecutar job
# Esperado: 
# - Detecta cambio
# - Reprocesa
# - Si pasa validaci√≥n ‚Üí estado cambia a "procesado"
```

#### Test 7.3: M√∫ltiples archivos en cuarentena
```bash
# Varios archivos en cuarentena, algunos modificados
# Ejecutar job
# Esperado: Solo reprocesa los modificados
```

#### Test 7.4: Deshabilitar reprocesamiento de cuarentena
```bash
# Configurar REPROCESS_INCLUDE_QUARANTINE=false
# Ejecutar job
# Esperado: No reprocesa archivos en cuarentena
```

### Criterios de √âxito
- ‚úÖ Detecta cambios en archivos en cuarentena
- ‚úÖ Reprocesa solo los modificados
- ‚úÖ No reprocesa si no hay cambios
- ‚úÖ Configurable (habilitar/deshabilitar)
- ‚úÖ Performance aceptable

### Archivos a Modificar
- `src/db/repositories.py`
- `src/pipeline/ingest_incremental.py`
- `.env.example` (documentar REPROCESS_INCLUDE_QUARANTINE)

---

## FASE 8: Manejo de Fechas en Texto Natural (3.3)

**Prioridad:** üü° MEDIA  
**Esfuerzo:** Medio  
**Riesgo de implementaci√≥n:** Bajo

### Objetivo
Manejar fechas extra√≠das en formato texto natural ("10 de enero 2025") que actualmente fallan en validaci√≥n.

### Implementaci√≥n

#### 8.1 Instalar dependencia
```bash
pip install dateparser
```

#### 8.2 Extender normalizaci√≥n de fechas
**Archivo:** `src/parser_normalizer.py`
- Modificar `normalize_date()` para incluir fallback
- Si formatos est√°ndar fallan ‚Üí usar `dateparser.parse()`
- Configurar `dateparser` para espa√±ol/espa√±ol de Espa√±a
- Si `dateparser` tambi√©n falla ‚Üí retornar `None`

#### 8.3 Agregar tests
**Archivo:** `tests/test_date_normalization.py` (NUEVO)
- Test: "10 de enero 2025" ‚Üí 2025-01-10
- Test: "veinte de marzo de dos mil veinticinco" ‚Üí 2025-03-20
- Test: Formatos est√°ndar siguen funcionando

### Pruebas

#### Test 8.1: Fecha en texto natural
```bash
# Procesar factura con fecha "10 de enero 2025"
# Esperado: 
# - Se parsea correctamente
# - Se guarda como 2025-01-10
# - Pasa validaci√≥n
```

#### Test 8.2: Formatos est√°ndar siguen funcionando
```bash
# Procesar facturas con formatos est√°ndar (DD/MM/YYYY, etc.)
# Esperado: Siguen funcionando como antes
```

#### Test 8.3: Fecha inv√°lida
```bash
# Procesar factura con fecha "fecha inv√°lida"
# Esperado: 
# - Retorna None
# - Factura va a "revisar" (no error)
```

#### Test 8.4: M√∫ltiples idiomas
```bash
# Procesar factura con fecha en ingl√©s "January 10, 2025"
# Esperado: Se parsea correctamente
```

### Criterios de √âxito
- ‚úÖ Parsea fechas en texto natural en espa√±ol
- ‚úÖ Formatos est√°ndar siguen funcionando
- ‚úÖ Maneja errores gracefully (None si no puede parsear)
- ‚úÖ No rompe funcionalidad existente
- ‚úÖ Performance aceptable (dateparser es r√°pido)

### Archivos a Modificar
- `src/parser_normalizer.py`
- `requirements.txt` (agregar dateparser)
- `tests/test_date_normalization.py` (NUEVO)

---

## ORDEN DE EJECUCI√ìN

1. **Fase 1** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Avanzar
2. **Fase 2** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Avanzar
3. **Fase 3** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Avanzar
4. **Fase 4** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Avanzar
5. **Fase 5** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Avanzar
6. **Fase 6** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Avanzar
7. **Fase 7** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Avanzar
8. **Fase 8** ‚Üí Pruebas ‚Üí ‚úÖ OK ‚Üí Completado

---

## CHECKLIST DE PRUEBAS GENERALES

Despu√©s de cada fase, ejecutar:

- [ ] Pruebas espec√≠ficas de la fase (ver secci√≥n de pruebas)
- [ ] Ejecutar job incremental completo sin errores
- [ ] Verificar logs no tienen errores inesperados
- [ ] Verificar que funcionalidad existente no se rompe
- [ ] Verificar estad√≠sticas se generan correctamente
- [ ] Verificar que no hay regresiones

---

## NOTAS IMPORTANTES

1. **Backup antes de cada fase:** Hacer backup de BD antes de migraciones
2. **Variables de entorno:** Documentar todas las nuevas variables en `.env.example`
3. **Logs:** Asegurar que todos los cambios tienen logging adecuado
4. **Documentaci√≥n:** Actualizar README.md con nuevas funcionalidades
5. **Rollback:** Cada fase debe ser reversible (especialmente migraciones de BD)

---

## ESTIMACI√ìN TOTAL

- **Fases ALTA prioridad (1-4):** ~8-12 horas
- **Fases MEDIA prioridad (5-8):** ~6-10 horas
- **Total estimado:** 14-22 horas

---

**Estado:** ‚è≥ Pendiente de inicio  
**√öltima actualizaci√≥n:** 9 de noviembre de 2025

